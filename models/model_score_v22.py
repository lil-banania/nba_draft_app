import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, mean_absolute_error
from sklearn.metrics import f1_score, precision_recall_fscore_support, precision_recall_curve
from sklearn.utils.class_weight import compute_class_weight
from scipy.stats import spearmanr
from imblearn.over_sampling import SMOTE
import warnings
warnings.filterwarnings('ignore')

# üìä CONFIGURATION ET CHARGEMENT DES DONN√âES
print("üèÄ NBA DRAFT 2025 - MACHINE LEARNING PIPELINE OPTIMIS√â")
print("=" * 60)

# Charger le dataset
df = pd.read_csv('nba_prospects_2025.csv')
print(f"Dataset charg√©: {df.shape[0]} joueurs, {df.shape[1]} features")

# üéØ D√âFINITION DES VARIABLES CIBLES
print("\nüéØ VARIABLES CIBLES D√âFINIES:")

# Cible 1: Talent G√©n√©rationnel (Classification Binaire) - VERSION CORRIG√âE
df['is_gen_talent'] = df['is_generational_talent'].astype(int)
print(f"‚úÖ V√âRIFICATION: {df['is_gen_talent'].sum()} talents g√©n√©rationnels d√©tect√©s")
print("Noms:", df[df['is_gen_talent'] == 1]['name'].tolist())

# Cible 2: Scout Grade (Classification Multi-classe)
grade_mapping = {'A+': 5, 'A': 4, 'A-': 3, 'B+': 2, 'B': 1, 'B-': 0, 'C+': -1, 'C': -2, 'C-': -3}
df['scout_grade_numeric'] = df['scout_grade'].map(grade_mapping)
print(f"‚úì Scout Grades: {df['scout_grade'].nunique()} cat√©gories")

# Cible 3: Elite Prospect (Top 10 pick)
df['elite_prospect'] = (df['predicted_rank_v22'] <= 10).astype(int)
print(f"‚úì Elite Prospects (Top 10): {df['elite_prospect'].sum()}/60 joueurs")

# üìã FEATURE ENGINEERING AVANC√â
print("\nüöÄ FEATURE ENGINEERING AVANC√â:")

# Features principales
core_features = [
    'ppg', 'rpg', 'apg', 'spg', 'bpg', 'turnovers',
    'fg_pct', 'three_pt_pct', 'ts_pct', 'usage_rate_calculated',
    'shooting_skill_score', 'athleticism_score', 'bbiq_score', 'leadership_score',
    'age', 'weight', 'final_draft_score_v21', 'score_v22'
]

available_features = [f for f in core_features if f in df.columns and df[f].notna().sum() >= 50]

# Features d√©riv√©es AM√âLIOR√âES
df['efficiency_ratio'] = df['ppg'] / (df['fga'] + 0.1)
df['playmaking_ratio'] = df['apg'] / (df['turnovers'] + 0.1)
df['two_way_impact'] = (df['ppg'] + df['rpg'] + df['apg'] + df['spg'] + df['bpg']) / 5

# NOUVELLES FEATURES AVANC√âES
df['efficiency_composite'] = (df['ts_pct'] * df['usage_rate_calculated']) / 100
df['clutch_factor'] = df['leadership_score'] * df['bbiq_score']
df['upside_potential'] = df['athleticism_score'] - df['age'] + 20

# Comparaisons avec moyennes par position
df['ppg_vs_avg'] = df['ppg'] / df.groupby('position')['ppg'].transform('mean')
df['ts_vs_avg'] = df['ts_pct'] / df.groupby('position')['ts_pct'].transform('mean')

# Indicateur Elite bas√© sur seuils
df['elite_indicator'] = (
    (df['ppg'] > df['ppg'].quantile(0.8)) &
    (df['ts_pct'] > df['ts_pct'].quantile(0.7)) &
    (df['athleticism_score'] > df['athleticism_score'].quantile(0.75))
).astype(int)

# Ajouter toutes les nouvelles features
new_features = ['efficiency_composite', 'clutch_factor', 'upside_potential', 
               'ppg_vs_avg', 'ts_vs_avg', 'elite_indicator']
available_features.extend(['efficiency_ratio', 'playmaking_ratio', 'two_way_impact'] + new_features)

print(f"‚úì {len(available_features)} features finales (incluant features avanc√©es)")

# üîß PREPROCESSING
print("\nüîß PREPROCESSING:")

X = df[available_features].fillna(df[available_features].median())
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
X_scaled = pd.DataFrame(X_scaled, columns=available_features)
print(f"‚úì Features standardis√©es")

# Fonction pour calculer Precision@K
def precision_at_k(y_true_ranks, y_pred_scores, k=10):
    top_k_pred_indices = np.argsort(y_pred_scores)[-k:]
    top_k_true_indices = np.argsort(y_true_ranks)[:k]
    intersection = len(set(top_k_pred_indices) & set(top_k_true_indices))
    return intersection / k

# ü§ñ MOD√àLE 1: D√âTECTION TALENTS G√âN√âRATIONNELS - VERSION OPTIMIS√âE
print("\n" + "="*60)
print("ü§ñ MOD√àLE 1: D√âTECTION TALENTS G√âN√âRATIONNELS (OPTIMIS√â)")
print("="*60)

y_gen = df['is_gen_talent']
print(f"Distribution: {y_gen.value_counts().to_dict()}")

# ENSEMBLE DE MOD√àLES pour plus de robustesse
models_gen = {
    'rf': RandomForestClassifier(n_estimators=300, max_depth=4, min_samples_leaf=1, 
                                class_weight={0: 1, 1: 8}, random_state=42),
    'gb': GradientBoostingClassifier(n_estimators=100, max_depth=3, learning_rate=0.1, 
                                    random_state=42),
    'lr': LogisticRegression(class_weight={0: 1, 1: 8}, C=0.1, max_iter=1000, 
                            random_state=42)
}

# Cross-validation stratifi√©e pour dataset petit
skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)

ensemble_predictions = []
ensemble_probabilities = []

print("\nüìä R√âSULTATS ENSEMBLE - TALENTS G√âN√âRATIONNELS:")

for name, model in models_gen.items():
    # Cross-validation
    cv_scores = cross_val_score(model, X_scaled, y_gen, cv=skf, scoring='f1')
    print(f"{name.upper()} F1 CV: {cv_scores.mean():.3f} (+/- {cv_scores.std() * 2:.3f})")
    
    # Entra√Æner sur toutes les donn√©es
    model.fit(X_scaled, y_gen)
    pred_proba = model.predict_proba(X_scaled)[:, 1]
    ensemble_probabilities.append(pred_proba)

# Pr√©diction ensemble (moyenne pond√©r√©e)
weights = [0.5, 0.3, 0.2]  # RF plus important
ensemble_proba = np.average(ensemble_probabilities, axis=0, weights=weights)

# POST-PROCESSING INTELLIGENT
def intelligent_post_processing(df, predictions_proba):
    adjusted_proba = predictions_proba.copy()
    
    # Boost pour grades A+ et A
    elite_mask = df['scout_grade'].isin(['A+', 'A'])
    adjusted_proba[elite_mask] *= 1.4
    
    # P√©nalit√© pour √¢ge > 20
    old_mask = df['age'] > 20
    adjusted_proba[old_mask] *= 0.8
    
    # Boost pour top 5 picks
    top_picks_mask = df['rank'] <= 5
    adjusted_proba[top_picks_mask] *= 1.2
    
    # Boost pour elite_indicator
    elite_ind_mask = df['elite_indicator'] == 1
    adjusted_proba[elite_ind_mask] *= 1.3
    
    return np.clip(adjusted_proba, 0, 1)

# Appliquer post-processing
final_proba_gen = intelligent_post_processing(df, ensemble_proba)

# Seuil optimal pour maximiser F1
precision_curve, recall_curve, thresholds = precision_recall_curve(y_gen, final_proba_gen)
f1_scores = 2 * (precision_curve * recall_curve) / (precision_curve + recall_curve + 1e-8)
optimal_threshold = thresholds[np.argmax(f1_scores[:-1])]  # Exclure le dernier point

print(f"\nüéØ SEUIL OPTIMAL: {optimal_threshold:.3f}")

# Pr√©dictions avec seuil optimal
y_pred_optimal = (final_proba_gen >= optimal_threshold).astype(int)
f1_optimal = f1_score(y_gen, y_pred_optimal)
precision_optimal, recall_optimal, _, _ = precision_recall_fscore_support(y_gen, y_pred_optimal, average='binary')

print(f"\nüèÜ R√âSULTATS OPTIMIS√âS:")
print(f"F1 Score: {f1_optimal:.3f}")
print(f"Precision: {precision_optimal:.3f}")
print(f"Recall: {recall_optimal:.3f}")

# Analyse des vrais talents g√©n√©rationnels
print(f"\nüîç ANALYSE DES VRAIS TALENTS:")
for idx, row in df[df['is_gen_talent'] == 1].iterrows():
    prob = final_proba_gen[idx]
    print(f"‚Ä¢ {row['name']}: Probabilit√© = {prob:.3f}")

# Feature importance (du mod√®le RF principal)
feature_importance_gen = pd.DataFrame({
    'feature': available_features,
    'importance': models_gen['rf'].feature_importances_
}).sort_values('importance', ascending=False)

print("\nüîù TOP 10 FEATURES - TALENTS G√âN√âRATIONNELS:")
for i, row in feature_importance_gen.head(10).iterrows():
    print(f"{row['feature']}: {row['importance']:.3f}")

# ü§ñ MOD√àLE 2: SCOUT GRADES (Gard√© identique)
print("\n" + "="*60)
print("ü§ñ MOD√àLE 2: PR√âDICTION SCOUT GRADES")
print("="*60)

y_scout = df['scout_grade_numeric'].dropna()
X_scout = X_scaled.loc[y_scout.index]

# Simplification des grades
def simplify_grade(grade_numeric):
    if grade_numeric >= 3: return "Elite"
    elif grade_numeric >= 0: return "Good" 
    else: return "Average"

df['scout_grade_simplified'] = df['scout_grade_numeric'].apply(simplify_grade)
y_scout_simple = df['scout_grade_simplified'].dropna()
X_scout_simple = X_scaled.loc[y_scout_simple.index]

print(f"Distribution simplifi√©e: {y_scout_simple.value_counts().to_dict()}")

try:
    X_train_scout, X_test_scout, y_train_scout, y_test_scout = train_test_split(
        X_scout_simple, y_scout_simple, test_size=0.3, random_state=42, stratify=y_scout_simple
    )
except ValueError:
    X_train_scout, X_test_scout, y_train_scout, y_test_scout = train_test_split(
        X_scout_simple, y_scout_simple, test_size=0.3, random_state=42
    )

gb_scout = GradientBoostingClassifier(n_estimators=100, max_depth=4, random_state=42)
gb_scout.fit(X_train_scout, y_train_scout)
y_pred_scout = gb_scout.predict(X_test_scout)

print("\nüìä R√âSULTATS - SCOUT GRADES:")
print(classification_report(y_test_scout, y_pred_scout, zero_division=0))

f1_macro = f1_score(y_test_scout, y_pred_scout, average='macro')
f1_weighted = f1_score(y_test_scout, y_pred_scout, average='weighted')
print(f"F1 Score (Macro): {f1_macro:.3f}")
print(f"F1 Score (Weighted): {f1_weighted:.3f}")

# ü§ñ MOD√àLE 3: SCORE COMPOSITE (Gard√© identique)
print("\n" + "="*60)
print("ü§ñ MOD√àLE 3: PR√âDICTION SCORE COMPOSITE")
print("="*60)

y_score = df['score_v22']
X_train_score, X_test_score, y_train_score, y_test_score = train_test_split(
    X_scaled, y_score, test_size=0.3, random_state=42
)

rf_score = RandomForestRegressor(n_estimators=100, max_depth=6, random_state=42)
rf_score.fit(X_train_score, y_train_score)
y_pred_score = rf_score.predict(X_test_score)

print(f"MAE: {mean_absolute_error(y_test_score, y_pred_score):.4f}")

# üéØ PR√âDICTIONS ET √âVALUATIONS FINALES
print("\n" + "="*60)
print("üéØ √âVALUATIONS FINALES OPTIMIS√âES")
print("="*60)

# Utiliser les pr√©dictions optimis√©es
df['pred_generational'] = final_proba_gen
df['pred_score'] = rf_score.predict(X_scaled)

# Scout grades
pred_simple = gb_scout.predict(X_scaled)
grade_mapping_reverse = {"Elite": 4, "Good": 1, "Average": -1}
df['pred_scout_grade'] = [grade_mapping_reverse[pred] for pred in pred_simple]

# M√âTRIQUES BUSINESS-ORIENTED
print("üìä M√âTRIQUES BUSINESS:")

# Top-K Recall pour talents g√©n√©rationnels
for k in [3, 5]:
    top_k_indices = np.argsort(df['pred_generational'])[-k:]
    top_k_recall = df.loc[top_k_indices, 'is_gen_talent'].sum() / df['is_gen_talent'].sum()
    print(f"Top-{k} Recall (Talents): {top_k_recall:.3f}")

# Precision@K pour ranking
prec_at_5 = precision_at_k(df['rank'], df['pred_score'], k=5)
prec_at_10 = precision_at_k(df['rank'], df['pred_score'], k=10)
print(f"Precision@5: {prec_at_5:.3f}")
print(f"Precision@10: {prec_at_10:.3f}")

# Corr√©lations
spearman_score, _ = spearmanr(df['pred_score'], df['score_v22'])
spearman_rank, _ = spearmanr(df['pred_score'], df['rank'])
print(f"Spearman (Score vs R√©el): {spearman_score:.3f}")
print(f"Spearman (Score vs Rank): {spearman_rank:.3f}")

# TOP PROSPECTS avec pr√©dictions optimis√©es
print("\nüåü TOP 10 PROSPECTS (PR√âDICTIONS OPTIMIS√âES):")
top_prospects = df.nlargest(10, 'pred_generational')[['name', 'position', 'pred_generational', 
                                                     'pred_score', 'scout_grade', 'rank']]
for i, row in top_prospects.iterrows():
    print(f"{row['rank']:2d}. {row['name']:<20} - Prob: {row['pred_generational']:.3f} - Score: {row['pred_score']:.3f}")

# R√âSUM√â FINAL
print("\n" + "="*60)
print("üìà R√âSUM√â PERFORMANCE OPTIMIS√âE")
print("="*60)

print("üéØ AM√âLIORATIONS APPORT√âES:")
print("‚Ä¢ Ensemble de 3 mod√®les pour robustesse")
print("‚Ä¢ Feature engineering avanc√© (6 nouvelles features)")
print("‚Ä¢ Post-processing intelligent avec r√®gles business")
print("‚Ä¢ Seuil optimal adaptatif")
print("‚Ä¢ M√©triques business-oriented")

print(f"\nüìä PERFORMANCES FINALES:")
print(f"‚Ä¢ F1 Talents G√©n√©rationnels: {f1_optimal:.3f}")
print(f"‚Ä¢ Top-3 Recall Talents: {df.loc[np.argsort(df['pred_generational'])[-3:], 'is_gen_talent'].sum() / 3:.3f}")
print(f"‚Ä¢ Precision@10: {prec_at_10:.3f}")
print(f"‚Ä¢ Spearman Ranking: {abs(spearman_rank):.3f}")

print("\nüöÄ PIPELINE OPTIMIS√â PR√äT POUR PRODUCTION!")
print("=" * 60)
